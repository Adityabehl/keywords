# KEYWORDS 

1. OPERATING SYSTEM(OS): An Operating system is system software that manages computer hardware and software resources and provides common services for computer programs. it act as an intermediary between users and computer hardware

    these are the famous or commonly used Operating System(OS):

      WINDOWS
      
      MACos
      
      LINUX

2.BARE METAL: Bare metal refers to a computer system or servers that runs without a layer of abstraction such as a virtulization layer or operating system. in this context, "bare metal" means the hardware is directly utilized for a single application or workload, allowing for maximum performance and control

3.LINUX KERNEL: The linux kernal is the core component of the linux operating system. it serves as the fundamental interface between a computer's hardware and its software. Here are key aspects of the linux kernal:

~kernal functions: it manages hardware resources such as CPU,Memory, and peripheral devices.

~modularity: the linux kernal is modular, meaning it can be extended with loadable modules that can be added or removed at runtime.

~open source: the linux kernel is open source, released under the GNU General Public License(GPL). this means its source code is freely available for anyone to inspect, modify and distribute.

~device drivers: the kernel includes drivers for a wide range of hardware devices, enabling the operating system to communicateT with and control peripherals like printers network cards, and graphics adapters.

4.Devices are mainly divided into three parts:

(i) COMPUTATION:-

~CPU:-The central processing unit (CPU) is the primary component of a computer that performs most of the processing tasks.often to referred to as the "brain" of the computer, the CPU executes instruction from proggrams through its control unit, arthmetic logic unit(ALU),and registers.


~GPU:-A Gaphics processing unit(GPU) is a specialized processor designed to handle and accelerate the rendering of images, video and animation. unlike a CPU,which is optimised for general-purpose computing task, a GPU is optimized for parllel processing,meaning it can handle many operations simultaneously.

~TPU:-A tensor processing unit(TPU) is a specialized type of processor designed by google specifically for accelerating machine learning task,particularly those involving tensor computations. Tensor are multimensional arrays used in various machine learning and artificial intelligence models.

~QPU:-A quantum processing unit(QPU) is a spcialized type of processor designed to perform quantum computations. unlike classical processor, which use bits to represent data as 0s and 1s, aQPU uses quantum bits or qubits, which can exist in multiple states simultaneously due to quantum superposition.

~ASIC:-ASIC stands for Application-Specific integrated circuit. it's a type of integrated circuit designed for a specific application or function, rather than general puerpose use. for example, an ASIC designed for cryptocurrency mining is specifically built to perform the hashing calculations required for mining.


(ii) STORAGE:-

~primary storage: RAM


~secondary storage: hard disk


(iii) NETWORK:-

~ Local Area Network (LAN): A LAN covers a small geographic area, such as a home, office, or campus. It connects devices within this limited space, typically using Ethernet cables or Wi-Fi. LANs are used for sharing resources like files, printers, and internet access.


~Wide Area Network (WAN): A WAN spans a large geographic area, often covering multiple cities, countries, or even continents. It connects multiple LANs and other types of networks. The internet is the largest example of a WAN. WANs can be public, like the internet, or private, like those used by large corporations.


5. OSI MODEL(7 LAYERS) NETWORKING MODEL
The OSI (Open Systems Interconnection) model is a conceptual framework used to understand and standardize the functions of a telecommunication or computing system, regardless of its underlying technology. It divides network communication into seven distinct layers, each with specific functions.


6.BLOCKCHAIN:
Blockchain is a decentralized digital ledger technology that securely records transactions across multiple computers in a way that prevents alteration or tampering. It operates as a chain of blocks, each containing a list of transactions. Once a block is added to the chain, it is difficult to change any information in that block without altering all subsequent blocks, which requires consensus from the network. This makes blockchain a transparent and secure method for managing and verifying transactions. It's commonly used in cryptocurrencies like Bitcoin but also has applications in various other fields, such as supply chain management, voting systems, and smart contracts.


7.CISC:

CISC architectures are designed to execute complex instructions with a rich set of addressing modes and operations, often simplifying programming and achieving high instruction density. However, this complexity can introduce challenges in decoding and execution that need to be managed effectively.


Examples:-

1️⃣ x86 Architecture: One of the most well-known CISC architectures, used in most personal computers. It includes a wide range of instructions and addressing modes.

2️⃣ AMD64 (x86-64): An extension of x86 that supports 64-bit computing, maintaining backward compatibility with x86 software.

8.RISC:

RISC architectures emphasize a simplified and highly optimized instruction set, with instructions typically executed in a single clock cycle. By relying on a large number of registers and implementing efficient pipelining, RISC processors aim to achieve high performance and efficiency. However, this simplicity can lead to a higher instruction count and potentially lower code density compared to more complex CISC architectures.


Examples:-

1️⃣ARM: A widely used RISC architecture, particularly in mobile devices and embedded systems. ARM processors are known for their power efficiency and high performance.

2️⃣MIPS: Another well-known RISC architecture used in various applications, including academic research and embedded systems.

3️⃣RISC-V: An open-source RISC architecture that is gaining popularity due to its flexibility and modular design.

9.RISC-V

RISC-V (pronounced "risk-five") is an open-source, RISC (Reduced Instruction Set Computer) architecture designed to be a flexible and extensible instruction set architecture (ISA). Developed at the University of California, Berkeley,its open nature, along with its base instruction set and extensibility, makes it an attractive choice for a wide range of applications, from embedded systems to high-performance computing. The growing community and ecosystem around RISC-V continue to drive innovation and adoption in various field.

image alt

10.ALGORITHM

An algorithm is a structured procedure or set of rules designed to solve a specific problem or perform a particular task. It involves well-defined, finite steps that take inputs and produce outputs. Algorithms are crucial for efficient computation and problem-solving, and they form the backbone of computer science and various applications in technology.


11.VIRTUAL MACHINE

A virtual machine (VM) is a software-based emulation of a physical computer that allows multiple operating systems or instances to run on a single physical machine. VMs provide isolation, encapsulation, and resource efficiency, making them valuable for development, testing, and production environments. They come in two main types: system virtual machines, which emulate entire systems, and process virtual machines, which abstract individual applications. While VMs offer numerous advantages, including flexibility and efficient resource utilization, they also come with performance overhead and management complexity.


12.IP ADDRESS

An IP address (Internet Protocol address) is a unique string of numbers separated by periods or colons that identifies each device connected to a network. IP addresses serve two primary functions: identifying the host or network interface and providing the location of the host in the network. They are essential for routing internet traffic and ensuring data reaches the correct destination.


There are two main versions of IP address:

1️⃣IPv4 (Internet Protocol version 4): This format uses four sets of numbers ranging from 0 to 255, separated by periods

(e.g., 192.168.1.1). It provides about 4.3 billion unique addresses.

2️⃣IPv6 (Internet Protocol version 6): This format uses eight groups of four hexadecimal digits separated by colons

(e.g., 2001:0db8:85a3:0000:0000:8a2e:0370:7334). It provides a vastly larger number of addresses to accommodate the growing number of devices on the internet.


13.ISP(Internet Service Provider)

An ISP, or Internet Service Provider, is a company or organization that provides individuals and businesses with access to the internet. ISPs offer various types of internet connections, including:

DSL (Digital Subscriber Line): Uses telephone lines to provide internet access.
Cable: Uses cable television lines for internet service.
Fiber-optic: Uses fiber-optic cables for high-speed internet access.
Satellite: Provides internet access via satellite signals, useful in remote areas.
Wireless: Uses radio signals to connect to the internet, which can include both fixed wireless and mobile broadband.
In addition to providing internet access, ISPs may also offer related services such as email, web hosting, and technical support. When you connect to the internet, you’re usually connecting through an ISP that assigns you an IP address and handles the routing of data between your device and the broader internet.


14.DNS(Domain Name System)

DNS stands for Domain Name System. It functions like a phone book for the internet, translating human-friendly domain names (like www.example.com) into IP addresses (like 192.0.2.1) that computers use to identify each other on the network.

Here's a simple breakdown of how DNS works:

Request: When you type a web address into your browser, a DNS request is made to find the corresponding IP address for that domain name.

Resolution: The DNS system then looks up the IP address associated with that domain name. This process involves several steps:

Recursive Resolver: Your request first goes to a DNS resolver, which is often provided by your ISP. This resolver tries to find the IP address for the domain name.
Root Name Servers: If the resolver doesn't have the address cached, it queries one of the root name servers, which point to the appropriate top-level domain (TLD) name servers (like those for .com or .org).
TLD Name Servers: The TLD servers then direct the resolver to the authoritative name servers for the specific domain.
Authoritative Name Servers: These servers have the actual IP address for the domain and respond to the resolver with this information.
Response: The DNS resolver returns the IP address to your browser, which then uses it to connect to the web server hosting the website you want to visit.

DNS is crucial for the functionality of the internet, making it easier for people to navigate and access websites without needing to remember complex numerical IP addresses.


15.VPN(Virtual Private Network)

A VPN, or Virtual Private Network, is a service that creates a secure, encrypted connection over a less secure network, such as the internet. It allows you to access the internet as if you were connected to a private network, providing privacy and security. Here's how it works and why you might use it:

Encryption: When you connect to a VPN, your internet traffic is encrypted, meaning that the data you send and receive is scrambled and unreadable to anyone who might intercept it. This helps protect your data from hackers, especially on public Wi-Fi networks.

IP Masking: A VPN hides your real IP address and replaces it with one from the VPN server. This can make it harder for websites, advertisers, and other parties to track your online activities and identify your location.

Secure Access: VPNs provide secure access to your network resources, which can be useful for businesses allowing remote employees to connect to internal systems securely.

Bypassing Restrictions: VPNs can help you access content that might be restricted or censored in your location by routing your connection through servers in different countries. This is useful for accessing services, websites, or content that might be geo-blocked.

Privacy: By hiding your IP address and encrypting your data, a VPN enhances your online privacy, making it more difficult for third parties to monitor your browsing activities.

When you use a VPN, your internet traffic is routed through a secure server before reaching its destination, adding a layer of privacy and security. However, it's important to choose a reputable VPN provider to ensure your data is handled securely and your privacy is protected.


16.FRONTEND,BACKEND AND API(Application Programming Interface)

In web development, the terms frontend, backend, and API refer to different aspects of building and managing applications. Here’s a breakdown of each:

Frontend
Frontend refers to the client-side of a web application. It encompasses everything that users interact with directly in their web browsers. This includes:

Design and Layout: The visual aspects of a website or application, including the layout, colors, fonts, and images.
User Interface (UI): The components that users interact with, such as buttons, forms, and navigation menus.
Technologies: Frontend development primarily involves languages and frameworks like HTML (Hypertext Markup Language), CSS (Cascading Style Sheets), and JavaScript. Frameworks and libraries like React, Angular, and Vue.js are commonly used to build interactive and dynamic user interfaces.
Backend
Backend refers to the server-side of a web application. It involves everything that happens on the server and is responsible for managing and processing data. Key aspects include:

Server: The hardware or software that provides services, resources, or data to other computers over a network.
Database: Where data is stored, retrieved, and managed. Common databases include MySQL, PostgreSQL, and MongoDB.
Server-Side Logic: The code that runs on the server, handling requests from the frontend, processing data, and sending responses. This includes server-side languages like Python, Ruby, Java, PHP, and Node.js.
Authentication: Managing user login, registration, and security.
API
API stands for Application Programming Interface. It is a set of rules and protocols that allows different software applications to communicate with each other. APIs can be used to:

Connect Frontend and Backend: APIs often serve as the bridge between the frontend (client-side) and backend (server-side). For instance, when you submit a form on a website, the frontend sends a request to the backend via an API, which processes the request and sends back a response.
Access External Services: APIs enable applications to interact with third-party services or data sources. For example, a weather app might use an API to fetch weather data from an external weather service.
Standardize Communication: APIs provide a standardized way for different software components or systems to interact, regardless of their underlying technology.
REST (Representational State Transfer) and GraphQL are common API design styles. REST APIs use HTTP requests to interact with resources, while GraphQL allows clients to request specific data and aggregate results from multiple sources.

In Summary
Frontend: The user-facing part of a web application where users interact directly.
Backend: The server-side part that processes data and handles the business logic.
API: A set of rules that allows different software components to communicate and exchange data.
Together, these components work to create a complete web application, with the frontend providing the user experience, the backend managing data and logic, and the API facilitating communication between the two.


17. NIC(Network Interface Card)
         A network interface card, also known as NIC or network interface controller, is typically a circuit board installed on the computer to connect to the network. It works as an indispensable component for the network connection of computers. Currently, NIC cards designed as a built-in style are commonly found in most computers and some network servers. Besides, NIC cards like server NICs can also be inserted into expansion slots of devices.

18. Ethernet
          Ethernet is a family of wired computer networking technologies commonly used in local area networks (LAN), metropolitan area networks (MAN) and wide area networks (WAN). It was commercially introduced in 1980 and first standardized in 1983 as IEEE 802.3


 19. Hypervisor
     A hypervisor is a software layer that allows multiple virtual machines (VMs) to run on the same physical machine. It's also known as a virtual machine monitor (VMM)
     #### >Types of hypervisor
 (i)Type 1

Also known as a bare-metal or native hypervisor, this type of hypervisor runs directly on the host's hardware. It's more secure and stable than Type 2 hypervisors, and is often used in enterprise data centers and server-based environments. Type 1 hypervisors can implement their own resource allocation strategies for virtual machines (VMs). Examples of Type 1 hypervisors include Microsoft Hyper-V, VMware vSphere, and KVM. 
 
(ii)Type 2

CLOUD SERVICES: 1.IAAS: 2.PAAS: 3.SAAS:

#INTRODUCTION OF AWS:

1.AWS SERVICES:
2.EC2-Elastic Cloud Computing
3.EBS-Elastic Block Store
4.Auto scaling 5.S3-Simple Storage Services
6.ELB-Elastic Load Balancer
7.IAM-Identity and Access Management
8.VPC – Virtual Private Cloud
9.DNS Route 53 - DNS
10.RDS – Relational Database Service

20.CREATE AN AWS ACCOUNT
THEN GO TO CONSOLE WHERE YOU FIND EC2.
THEN CLICK ON LAUCH INSTANCE, WHERE YOU HAVE TO ENTER THE NAME ATG{XYZ}.
AFTER THAT SELECT THE OPERATING SYSTEM , THEN CLICK ON FREE TIRE ELIGBLE.
NOW YOU HAVE TO CREATE NEW KEY PAIR , WHERE AS KEY PAIR ARE PUBLIC OR PRIVATE. ALSO SELECT THE .PPK THEN PRESS ENTER TO CREATE.DOWNLOAD THE KEY PAIR AND SAVE IT IN DESKTOP ALSO.
NOW YOU WILL SEE THE RAM AND CPU WHICH IS GIVEN BY AWS.
NOW ALLOW SSH AND HTTP.
AFTER ALL THIS STEPS THEN CLICK ON THE LAUNCH INSTANC AND CLICK ON ALL INSTANCE.
NOW YOU CAN SEE YOUR CREATED YOUR INSTANCE AND IP ADDRESS.
COPY YOUR IP ADDRESS AND PASTE IT IN NEW TAB , YOU WILL FIND NOTHING BECAUSE THEIR IS NO SERVER PRESENT.
TO CREATE SERVER INSTALL PUUTY.
OPEN PUTTY WHERE FIRST GO TO SESSION AND ENTER YOUR IP ADDRESS.
THEN GO SSH THEN AUTH THEN CREDITALS .
WHERE YOU HAVE TO CLICK ON BROWSE WEHRE SELECT THE KEY PAIR FILE WHICH IS PRESENT IN DESKTOP.
NOW GO TO SESSION AND CLICK ON OPEN
YOUR VM IS CREATED.
TO OPEN A WEB SERVER---
1.TYPE ON GOOGLE HOW TO INSTALL WEB SERVER IN YOUR OS WHICH YOU HAVE SELECTED.
2.NOW DOWNLOAD ANY WEB SERVER LIKE APACHE2ETC.
3.FROM THAT INSTALL APACHE2 IN YOUR VM
TYPE : >>sudo apt update
sudo apt install apache2


---PRESS ENTER AND WEB SERVER WILL START INSTALLING----
4.TO SEE THE WEB SERVER GO TO GOOGLE OPEN NEW TAB AND ENTER YOU IP ADDRESS . YOU WILL SEE THE APACHE2 WEB SERVER.
-----------TO SEE HI ON SERVER ---------------
1.ENTER THE FOLLOWING COMMAND
>>cd{ENTER SPACE}/var/www/html/
>>ls
>>YOU WILL SEE
>>index.html
------TO REMOVE SUDO-----------
>>sudo su
--------NOW SUDO IS REMOVED--------

-------REMOVE THE APACHE2 SERVER -----------
>>rm index.html
------THEN ENTER--------
>>vi index.html
------PRESS {i} -------
----------ENTER----------
>> hi
------NOW PRESS THESE KEY-------
>>ctrl+c
>>shift+";"
>>wq
-------PRESS ENTER -------
NOW GO TO GOOGLE AND ENTER THE IP ADDRESS YOU WILL SEE HII
---------------------------------------------------------------------------------------------------------------------




## USING CONTAINER's IN VM , USNIG DOCKER TO ADD NGINX SEVER IN IT AND TYPING HI IN WEB SERVER

        1.First I login in my AWS account . Thne I created an instance .
        2.In instance I make some changes , where I edit in network setting , where I added SSH , HTTPS , HTTP, ALL TRAFFIC , ALL TCP , ALL UDP AND CREATED AN INSTANCE.
        3.Then I open puuty add the IP address from instance and add key pair file which I have downloaded when I creating instance.
        4.After that I click on open , then my ubuntu terminal was opended , where I logined by writting ubuntu.
        5.After that I have to install docker in my OS .
        6.Then , I enter few command to install the docker
        COMMANDS ARE:
        curl -sL https://github.com/ShubhamTatvamasi/docker-install/raw/master/docker-install.sh | bash
        newgrp docker # this command will help us to use docker
        3.docker ps # provides a list of the Docker containers on your machine
        docker --version # to check the version of docker which is installed
        docker pull nginx #TO use nginx server in container
        docker run --name docker-nginx -p 80:80 nginx #In a web browser, enter your server’s IP address to reveal Nginx’s default landing page
        ctrl + c #to stop the container from running
        docker ps -a #The output reveals that the Docker container has exited
        DETACHED MODE
        docker run --name docker-nginx -p 80:80 -d nginx #output is the container’s ID
        docker ps # provoide new information about container
        docker stop docker-nginx # to stop the container
        docker rm docker-nginx
        Building a Web Page to Serve on Nginx
        mkdir -p ~/docker-nginx/html # Create a new directory for the website content within the home directory
        cd ~/docker-nginx/html # Create an HTML file to serve on the server
        ls
        cd html/
        18.ls # will show index.html file
        19.sudo vi index.html
        press {"i"} # help to insert in the web server
        hi # write whatever you want to write I write only hi
        ctrl + c
        shift + ;
        wq press {ENTER}
        docker run --name docker-nginx -p 80:80 -d -v ~/docker-nginx/html:/usr/share/nginx/html nginx # Linking the container to the VM
        
        Also known as a hosted hypervisor, this type of hypervisor runs on top of an operating system as a software layer or application. Type 2 hypervisors are easier to install, configure, and use than Type 1 hypervisors, and are more user-friendly. However, Type 2 hypervisors are less efficient than Type 1 hypervisors because they negotiate resource allocation with the operating system. Examples of Type 2 hypervisors include VMware Workstation, Oracle VirtualBox, and Parallels Desktop

21.Primary and Secondary Memory
        Primary memory and secondary memory are two main categories of computer memory, each with distinct characteristics.
        
        Primary Memory (Main Memory)
        Volatile: Data stored in primary memory is lost when the computer is turned off.
        Fast access: Primary memory provides very fast access to data.
        Smaller capacity: Compared to secondary memory, primary memory has a smaller capacity.
        Examples: RAM (Random Access Memory)
        Secondary Memory
        Non-volatile: Data stored in secondary memory is retained even when the computer is turned off.
        Slower access: Secondary memory access is generally slower than primary memory.
        Larger capacity: Secondary memory can store significantly more data than primary memory.
        Examples: Hard disk drives (HDDs), solid-state drives (SSDs), optical drives (CDs, DVDs)
        In essence, primary memory is used for active data that the CPU needs to access quickly, while secondary memory is used for long-term storage of data.

22.Computer Network
    Basic Network Concepts:
        Local Area Network (LAN): A network that connects devices within a limited geographic area, such as a home, office, or school.
        Wide Area Network (WAN): A network that connects computers over a large geographic area, such as a city, state, or country.
        Internet: A global network of interconnected computers and networks.
        Intranet: A private network within an organization that uses Internet technologies.
        Extranet: A private network that allows authorized external users to access an organization's resources.
   A) Network Components:
        Network components are essential for connecting computers to each other and to the internet. They enable communication and data sharing between devices. Here are some of the key network components:

   B) Hardware Components:
        Network Interface Card (NIC): A physical component that connects a computer to a network. It can be built into the motherboard or added as a separate card.
        Router: A device that connects multiple networks together. It directs data packets to their correct destinations.
        Switch: A device that connects multiple devices within a local area network (LAN). It forwards data packets based on their destination addresses.
        Modem: A device that connects a computer to the internet through a telephone line or cable connection.
        Hub: A simple device that broadcasts data packets to all connected devices.
  C)  Software Components:
        Network Operating System (NOS): Software that manages network resources and communication.
        Network Protocols: Rules and standards that govern how data is transmitted over a network. Examples include TCP/IP, HTTP, and FTP.
        Network Drivers: Software that enables communication between the operating system and network hardware.
        These components work together to create a network infrastructure that allows computers to communicate and share data. The specific components used will depend on the size and complexity of the network.

23.Network Protocols:
        TCP/IP (Transmission Control Protocol/Internet Protocol): The foundation of the internet. It defines how data is transmitted and received.
        HTTP (Hypertext Transfer Protocol): Used for transferring web pages and other data on the internet.
        FTP (File Transfer Protocol): Used for transferring files between computers.
        SMTP (Simple Mail Transfer Protocol): Used for sending and receiving email.
        DHCP (Dynamic Host Configuration Protocol): Automatically assigns IP addresses to devices on a network.
        Network Security:
        Firewall: A security system that controls network traffic.
        VPN (Virtual Private Network): A secure tunnel that allows users to access a network remotely.
        Encryption: The process of encoding data to make it unreadable to unauthorized users.
        Fundamental Concepts:
        IP Address (Internet Protocol Address): A unique numerical label assigned to each device connected to a network. It allows devices to communicate with each other.  
        DNS (Domain Name System): Translates human-readable domain names (like [invalid URL removed]) into numerical IP addresses.
        ISP (Internet Service Provider): A company that provides internet access to individuals and organizations.
        IP Versions:
        IPv4 (Internet Protocol version 4): The older version of IP, using 32-bit addresses.
        IPv6 (Internet Protocol version 6): The newer version of IP, using 128-bit addresses. It was introduced to address the depletion of IPv4 addresses.
        Other Network Terms:
        NAT (Network Address Translation): Allows multiple devices on a private network to share a single public IP address.
        MAC Address (Media Access Control Address): A unique identifier assigned to a network interface card.
        Network Adresses:
        A network address is a unique identifier assigned to a device on a network. It allows devices to communicate with each other by providing a specific location or address within the network.
        
        There are three main types of network addresses:
        
        1. Transport Layer - Port Address:
        Purpose: Identifies specific applications or processes running on a device.
        Format: A 16-bit number (0 to 65535).
        Example: A web server might use port 80, while an email server might use port 25.
        2. Network Layer - IP Address:
        Purpose: Uniquely identifies a device on a network.
        Format: IPv4 (32-bit) or IPv6 (128-bit).
        Example: IPv4: 192.168.1.100, IPv6: 2001:0db8:85a3:0000:0000:8a2e:0370:7334
        3. Data Link Layer - MAC Address:
        Purpose: A unique physical address burned into a network interface card (NIC).
        Format: 48-bit hexadecimal number (e.g., 00:11:22:33:44:55).
        Example: Used for communication within a local area network (LAN).
        How it works?
        When a device wants to communicate with another device on a different network, it uses the IP address of the destination device. The IP address is then used to find the MAC address of the destination device, which is used to physically transmit the data. The port address is used to specify the specific application or process that the data is intended for.
        
        Fun Fact
        If you type the following link with ':80' already added to it, it will still open Google.com.
        http://google.com:80
        
        (Click on the link to try it!)

    Why does this happen?
    Here's why:
    
    Default Port for HTTP: By default, web browsers use port 80 for communication with websites that use the Hypertext Transfer Protocol (HTTP).
    Implicit vs. Explicit Port: When you enter a website address (URL) like "[invalid URL removed]", the port number 80 is assumed by the browser. It's like a shorthand.
    Explicit Port: If you explicitly specify the port number, like "http://google.com:80", the browser still understands and uses port 80 to connect to the website.
    So, both ways (with or without the port number) will successfully open Google.com in your web browser.
    
    OSI Model: A Framework for Networking
    OSI (Open Systems Interconnection) is a reference model that defines how different layers of a network interact with each other. It provides a conceptual framework for understanding the various components and protocols involved in network communication.
    
    The OSI model consists of seven layers:
    
    1. Physical Layer: Deals with the physical transmission of data, including hardware components like cables and network interfaces.
    2. Data Link Layer: Handles error detection and correction, as well as framing data into packets.
    3. Network Layer: Responsible for routing data packets between networks.
    4. Transport Layer: Ensures reliable delivery of data, including flow control and error recovery.
    5. Session Layer: Manages sessions between communicating devices.
    6. Presentation Layer: Handles data formatting and encryption.
    7. Application Layer: The top layer that interacts directly with user applications, such as web browsers and email clients.
    Each layer builds upon the services provided by the layer below it. For example, the Application Layer relies on the services of the Presentation Layer, which in turn relies on the Session Layer, and so on.
    
    While the OSI model is a theoretical framework, it provides a valuable tool for understanding network concepts and troubleshooting network issues.
    
    Operating Systems: The Foundation of Computing
    Operating systems are the software that manage a computer's hardware and resources. They provide a platform for applications to run and interact with the computer's hardware.

24.Functions of Operating Systems:
        Resource management: Allocating and managing system resources such as CPU, memory, storage, and input/output devices.
        Process management: Creating, scheduling, and managing processes (running programs).
        Memory management: Allocating and managing memory space for processes.
        File system management: Organizing and managing files and directories on storage devices.
        User interface: Providing a way for users to interact with the computer.
        Major Operating Systems:
        Windows: A popular operating system developed by Microsoft, primarily used for personal computers and servers. It's programmed primarily in C, C++, C#, and other Microsoft-specific languages.
        macOS: A proprietary operating system developed by Apple for its Macintosh computers. It's known for its user-friendly interface and integration with Apple devices. Primarily programmed in C, C++, Objective-C, and Swift.
        Linux: A family of open-source operating systems based on the Linux kernel. It's highly customizable and widely used in servers, embedded systems, and supercomputers. Primarily programmed in C, C++, and various other languages.
        Some popular distributions of Linux:
25. Desktop Distributions:
        Ubuntu: A popular choice for beginners and experienced users alike, known for its ease of use and extensive community support.
        Mint: Another user-friendly distribution based on Ubuntu, offering a more traditional desktop experience.
        Server Distributions:
        Debian: A stable and reliable distribution often used for servers and network infrastructure.
        Red Hat Enterprise Linux: A commercial distribution known for its stability and enterprise-grade support.
        Other Notable Distributions:
        Arch Linux: A rolling release distribution known for its flexibility and customization options.
        Kali Linux: A distribution designed for penetration testing and security auditing.
        Android: A mobile operating system based on Linux, used by most smartphones and tablets. It's known for its open-source nature and flexibility. Primarily programmed in Java, C, and C++.
        iOS: A mobile operating system developed by Apple for its iPhone and iPad devices. It's known for its seamless integration with Apple's ecosystem. Primarily programmed in C, C++, Objective-C, and Swift.
26. Kernel
    A kernel is the core component of an operating system. It's responsible for managing the computer's hardware resources, handling communication between hardware and software, and providing a platform for applications to run.
27.Bare Metal System
        A bare-metal system is a computer system that operates directly on the hardware without the use of an operating system. This means that the software running on the system has direct access to the hardware resources, such as the CPU, memory, and Input/Output devices.
        In simpler terms, it's like running a car without a driver: the engine and other components are working directly, without any intermediary system to manage them.
28.Cloud Computing
        Cloud computing is the delivery of computing services—including servers, storage, databases, networking, software, analytics, and intelligence—over the Internet ("the cloud"). This allows for faster innovation, flexible resources, and economies of scale.  
        In simpler terms, it means accessing computing resources from a remote location, often through the internet. Instead of owning your own hardware, you can rent it from a cloud provider. Think of it like renting a car instead of buying one. You get to use it when you need it without the hassle of maintenance or ownership. This can be beneficial for businesses and individuals alike, as it can reduce costs, increase flexibility, and improve scalability.
        Examples of Cloud Computing:
        
        Cloud storage: Storing files and documents online, like Google Drive or Dropbox.
        Cloud applications: Using software like Microsoft Office 365 or Google Workspace without installing it on your computer.
        Cloud servers: Renting virtual servers for hosting websites or running applications.
29.Virtual Machine
    A virtual machine (VM) is like a computer within a computer. It's a software-based environment that simulates a physical computer, complete with its own CPU, memory, storage, and network interface.
    Think of it like having multiple computers running on a single physical machine. Each virtual machine can run its own operating system and applications independently, as if it were a separate physical computer.
    Here's a simple example: Imagine you're a web developer working on a project that requires different programming languages and environments. You could create multiple virtual machines on your computer, each running a different operating system and development tools. This allows you to isolate your projects and avoid conflicts between different environments.
  30.  Algorithm
    In simple terms, an algorithm is a set of instructions that a computer follows to solve a problem or perform a task. It's like a recipe for a computer, outlining the steps needed to achieve a specific outcome.  
    Here's a real-world example:
    
    Recipe: To make a sandwich, you follow a set of steps: get bread, add filling, put the top slice on.  
    Algorithm: A computer program might use an algorithm to find the shortest route between two points on a map.  
    Key points about algorithms:
    
    They are a sequence of well-defined steps.
    They have a clear input and output.
    They must terminate after a finite number of steps.
    They must be correct and produce the desired result.
    Algorithms are the foundation of computer science and are used in everything from search engines to artificial intelligence.

31.Kubernetes
    Kubernetes is an open-source platform designed to automate the deployment, scaling, and management of containerized applications.
    It makes it easier to deploy and run applications in a scalable and reliable way.
    Kubernetes is widely used for deploying and managing cloud-native applications.
    It is particularly well-suited for microservices architectures, where applications are broken down into smaller, independent components.
32.API (Application Programming Interface)
    API stands for Application Programming Interface. It's like a set of rules or guidelines that allow different software programs to communicate with each other. Think of it as a bridge between two applications, allowing them to share data and functionality.
    Here's a simple example:
    Imagine you're using a weather app on your phone. The app doesn't have its own weather data; instead, it uses an API provided by a weather service to get the current weather information. The app sends a request to the weather service's API, and the API sends back the weather data in a format that the app can understand.
    In essence, APIs make it easier for developers to create new applications and services by leveraging existing functionality from other applications.
    
    Types of APIs and Examples
    There are several types of APIs, each with its own purpose and characteristics:
    Public APIs
    
    Open to the public: Anyone can use these APIs to build applications or services.
    Examples:
    Google Maps API (2005): Allows developers to integrate maps into their applications.
    Twitter API (2006): Enables developers to create applications that interact with Twitter.
    YouTube Data API (2007): Provides access to YouTube data and functionality.
    Private APIs
    
    Internal use only: These APIs are restricted to use within an organization.
    Examples:
    A company's internal API for accessing customer data.
    A banking app's internal API that allows different parts of the app to communicate securely and efficiently.
    Partner APIs
    
    Shared with specific partners: These APIs are made available to select partners or customers.
    Examples:
    A payment gateway API used by e-commerce platforms.
    A shipping carrier API used by online retailers.
    RESTful APIs
    
    Follow Representational State Transfer (REST) principles: These APIs use HTTP methods (GET, POST, PUT, DELETE) to interact with resources.
    Examples:
    Most modern web APIs, such as those provided by social media platforms and cloud services.
    Date Introduced: Early 2000s.
    SOAP APIs
    
    Use Simple Object Access Protocol (SOAP): SOAP APIs are typically more complex and verbose than RESTful APIs.
    Examples:
    Older enterprise applications and legacy systems often use SOAP APIs.
    Date Introduced: 1998.
    GraphQL APIs
    
    A query language for APIs: GraphQL allows clients to specify the exact data they need, reducing over-fetching and under-fetching.
    Examples:
    Many modern web applications and APIs are adopting GraphQL, such as Facebook and GitHub.
    Date Introduced: 2015.
    gRPC APIs
    
    A modern, high-performance RPC (Remote Procedure Call) framework.
    Uses HTTP/2 for transport and Protocol Buffers for serialization.
    Examples:
    Commonly used in microservices architectures for efficient communication between services.
    Date Introduced: 2016.
    The choice of API type depends on various factors, including the desired level of access, the complexity of the data, and the target audience.

33.Programming Languages
    Programming languages are the tools used to create software applications. Each language has its own strengths and weaknesses, making them suitable for different types of projects.
    Popular Programming Languages
    Python: A versatile language used for web development, data science, machine learning, and automation.
    JavaScript: The language of the web, used for creating interactive web pages and applications.
    Java: A general-purpose language used for web development, enterprise applications, and Android app development.
    C++: A powerful language used for systems programming, game development, and high-performance computing.
    C#: A language developed by Microsoft, primarily used for Windows applications and game development.
    Ruby: A dynamic language often used for web development and scripting.
    PHP: A popular language for web development, especially for creating dynamic websites.
    Swift: A modern language developed by Apple for iOS and macOS app development.
    Front-end vs. Back-end Development
    Front-end development: Involves creating the user interface of a web application, including the design, layout, and interaction. Languages commonly used for front-end development include HTML, CSS, and JavaScript.
    Back-end development: Involves the server-side logic of a web application, such as database management, data processing, and API development. Languages commonly used for back-end development include Python, Java, C#, Ruby, and PHP.
34.Blockchain
    Blockchain is a decentralized database that uses cryptography to secure and verify data.
    Unlike traditional databases, blockchain data is immutable, meaning it cannot be changed once recorded. This makes it highly secure and transparent.
    Blockchain has a wide range of applications, including cryptocurrency, supply chain management, voting systems, and more.
    While it offers many benefits, challenges such as scalability, energy consumption, and regulatory concerns remain to be addressed.
    DSA (Data Structures and Algorithms)
    DSA (Data Structures and Algorithms) is the foundation of computer science. It's like the blueprint for building efficient and effective software.
    Data Structures
    They are the fundamental building blocks of computer programs.
    They define how data is organized, stored, and manipulated within a computer program.
    Essentially, they provide a blueprint for efficiently accessing and using data.
    Key characteristics of data structures include:
    Organization: How data is arranged and related to other data elements.
    Storage: The way data is physically stored in memory.
    Operations: The functions or methods that can be applied to the data.
    Common data structures include:
    Arrays: An ordered collection of elements with a fixed size.
    Example: An array of integers to store daily temperatures.
    Linked lists: Elements linked together using pointers.
    Example: A linked list of customers in a database.
    Stacks: LIFO (Last-In-First-Out) data structure.
    Example: Undo/redo functionality in software.
    Queues: FIFO (First-In-First-Out) data structure.
    Example: A waiting line for a ticket.
    Trees: Hierarchical structures with nodes and edges.
    Example: File system, family tree.
    Graphs: Networks of nodes connected by edges.
    Example: Social networks, road maps.
    Choosing the right data structure is crucial for efficient algorithm design and program performance.
35.Algorithms
    Algorithms are step-by-step procedures or instructions used to solve problems or perform tasks. They provide a systematic approach to achieving a specific goal.
    Key characteristics of algorithms include:
    Input: The data or information that the algorithm processes.
    Output: The result or solution produced by the algorithm.
    Finiteness: The algorithm should terminate after a finite number of steps.
    Definiteness: Each step should be precisely defined and unambiguous.
    Effectiveness: The algorithm should produce the correct output for all valid inputs.
    Examples of algorithms:
    Searching algorithms:
    Linear search: Iterates through elements one by one.
    Binary search: Efficiently searches a sorted array.
    Sorting algorithms:
    Bubble sort: Swaps adjacent elements until the list is sorted.
    Quick sort: A divide-and-conquer algorithm that partitions the array and recursively sorts the partitions.
    Merge Sort: A divide-and-conquer algorithm that divides the array into smaller subarrays, sorts them, and merges them back together.
    Graph algorithms:
    Breadth-first search (BFS): Explores nodes level by level.
    Depth-first search (DFS): Explores nodes along a path until a leaf is reached.
    Dynamic programming: Breaks down problems into smaller subproblems and stores the solutions to avoid redundant calculations.
    Algorithms are essential for computer science and are used in a wide range of applications, from simple calculations to complex AI systems.
36.DBMS (Database Management System)
    It is a software system that manages databases.
    It provides a way to store, retrieve, update, and manage data efficiently.
    Key functions of a DBMS:
    Data storage: Stores data in a structured format, such as tables, rows, and columns.
    Data retrieval: Allows users to query and retrieve data from the database.
    Data manipulation: Provides tools for updating, inserting, and deleting data.
    Data security: Implements mechanisms to protect data from unauthorized access.
    Concurrency control: Manages simultaneous access to the database by multiple users.
    Recovery: Ensures data integrity and consistency in case of failures.
    Examples of popular DBMS:
    Relational DBMS:
    MySQL
    PostgreSQL
    Oracle
    Microsoft SQL Server
    NoSQL DBMS:
    MongoDB
    Cassandra
    Redis
    Neo4j
    Choosing the right DBMS depends on the specific requirements of the application, such as the type of data, the expected volume of data, and the performance needs.

37.Compiler
    A compiler translates high-level programming language code into machine code that can be executed by a computer.
    Example: A C++ compiler translates C++ code into machine code that can be run on a specific processor.
    Assembler
    An assembler translates assembly language code into machine code. Assembly language is a low-level language that is closer to machine code than high-level languages.
    Example: The GNU Assembler (GAS) is a popular assembler for various architectures.
    Assembly Language
    Assembly language is a low-level programming language that uses mnemonics to represent machine code instructions.
    It's a step closer to machine code than high-level languages like C, C++, or Python.
    Here's a simple example of assembly language code:
    MOV AX, BX ; Move the value in register BX to register AX
    ADD AX, CX ; Add the value in register CX to register AX
    JMP LOOP ; Jump to the label LOOP
    In this example, MOV, ADD, and JMP are mnemonics that represent specific machine instructions. The registers AX, BX, and CX are used to store data.

38.Key points about assembly language:
    Low-level: It's closer to machine code than high-level languages.
    Platform-specific: Assembly language is specific to a particular processor architecture.
    Efficient: It can be used to write highly optimized code.
    Difficult to read and write: Assembly language can be complex and difficult to understand.
    Assembly language is often used for:
    Systems programming: Creating operating systems, device drivers, and other low-level software.
    Performance optimization: Improving the efficiency of critical code sections.
    Reverse engineering: Analyzing the code of existing programs.
    While assembly language is less common for general-purpose programming, it's still a valuable tool for understanding how computers work at a fundamental level.

39.Interpreter
    An interpreter executes high-level programming language code directly, without first translating it into machine code. It can execute code line by line, making it suitable for debugging and prototyping.
    Example: Python and JavaScript are often interpreted languages.
    Linker/Loader
    A linker combines object files (generated by a compiler) and libraries into an executable program. A loader loads the executable program into memory for execution.
    Example: The GNU linker (ld) is a commonly used linker for various operating systems.
    In summary:
    Compiler: High-level language to machine code.
    Assembler: Assembly language to machine code.
    Interpreter: Executes high-level language code directly.
    Linker/Loader: Combines object files and libraries into an executable program.
    These tools work together in the process of creating and running software applications.

40.Semiconductors
    Semiconductors are materials that have electrical conductivity between that of a conductor and an insulator. This unique property allows them to be used as switches, amplifiers, and other electronic components.
    They have revolutionized the electronics industry, enabling the development of smaller, faster, and more efficient devices.
    Semiconductors are used in a wide range of electronic devices, including:
    Transistors: The fundamental building blocks of modern electronics.
    Integrated circuits (ICs): Combinations of transistors and other components on a single silicon chip.
    Microprocessors: Complex integrated circuits that perform the functions of a computer's central processing unit (CPU).
    Microcontrollers: Smaller, simpler processors often used in embedded systems.
    Sensors: Devices that convert physical quantities into electrical signals.
    LEDs (Light-Emitting Diodes): Efficient light sources.
    Solar cells: Devices that convert sunlight into electricity.
    Examples of Semiconductors:
    Silicon: The most commonly used semiconductor material.
    Germanium: Another widely used semiconductor.
    Gallium Arsenide: Used in high-speed devices and optoelectronics.
    Indium Phosphide: Used in fiber-optic communications and laser diodes.
    Semiconductor Manufacturing Companies:
    Intel: One of the largest semiconductor manufacturers, producing a wide range of processors and other components.
    AMD: A major competitor to Intel, specializing in processors and graphics cards.
    TSMC (Taiwan Semiconductor Manufacturing Company): The world's largest semiconductor foundry, manufacturing chips for companies like Apple, Qualcomm, and Nvidia.
    Samsung: A South Korean conglomerate that also manufactures semiconductors, including memory chips and processors.
    ASML (ASML Holding NV): A Dutch company that produces lithography machines, which are essential for manufacturing semiconductors.
    GlobalFoundries: A global semiconductor foundry that offers a wide range of manufacturing services.
    These companies, along with many others, play a crucial role in the global semiconductor industry, producing the components that power our modern world.
    The semiconductor industry is a vital part of the global economy, and advances in semiconductor technology continue to drive innovation in various fields.
    FAB (Semiconductor Fabrication Facility)
    FAB is a common abbreviation for semiconductor fabrication facility or foundry. It's a manufacturing facility where semiconductors are produced.
    These facilities are highly specialized and require complex equipment and processes to create the intricate patterns and structures found in semiconductors.
    Think of a FAB as a factory that produces the tiny chips you find in everything from smartphones to computers and cars. They are responsible for manufacturing the integrated circuits (ICs) that power our modern technology.

41.DevOps
    DevOps is a set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration between developers and IT professionals, automating and streamlining the processes of software development, testing, deployment, and infrastructure management.
    The goal is to shorten the software development lifecycle while delivering high-quality software continuously.
    Key aspects of DevOps:
    Collaboration: Fosters communication and cooperation between development and operations teams.
    Automation: Uses tools and scripts to automate repetitive tasks, reducing manual effort and errors.
    Continuous Integration (CI): Regularly merging code changes into a shared repository and testing them automatically.
    Continuous Delivery (CD): Automatically deploying software changes to production environments.
    Infrastructure as Code (IaC): Treating infrastructure as code, allowing for automated provisioning and management.
    Monitoring and Feedback: Continuously monitoring the performance and health of applications and providing feedback for improvement.
Benefits of DevOps:
    Faster delivery of software: By automating processes and improving collaboration, DevOps teams can deliver new features and updates more quickly.
    Improved quality: Continuous testing and feedback help to identify and fix issues early in the development process.
    Increased reliability: DevOps practices can help to improve the reliability and stability of software systems.
    Enhanced customer satisfaction: Faster delivery and improved quality can lead to better customer experiences.
    Examples of DevOps Tools:
    1. Jenkins: A popular CI/CD tool used to automate software builds, tests, and deployment.
    2. Docker: A containerization platform that allows applications to run consistently across different environments.
    3. Kubernetes: An open-source platform to automate deploying, scaling, and operating application containers.
    4. Git: A version control system used to track changes in the source code during development.
    5. Ansible: An IT automation tool used for configuration management, application deployment, and task automation.
    6. Prometheus: A monitoring tool for collecting and analyzing metrics from various services.
    7. Terraform: An infrastructure as code tool used for managing cloud resources through configuration files.
    DevOps is a cultural shift that requires organizations to adopt new practices, tools, and mindsets. By embracing DevOps, organizations can achieve significant benefits in terms of efficiency, quality, and time-to-market.

42.TOR (The Onion Router) Browser
    TOR (The Onion Router) Browser is a web browser that uses a specialized type of VPN called the TOR network to protect your privacy and anonymity online.
    The TOR network consists of thousands of volunteer-operated servers, known as relays, that are distributed around the world.
    When you use TOR, your traffic is routed through multiple relays, making it difficult for anyone to track your online activity.
    Key features of TOR Browser:
    Anonymity: Hides your IP address and browsing history.
    Privacy: Protects your online identity and prevents tracking.
    Accessibility: Allows you to access websites that may be blocked or censored in your region.
    Security: Encrypts your traffic to protect against eavesdropping.
    This browser is often used by journalists, activists, and individuals who want to protect their privacy online.
    How TOR works:
    Your computer connects to a random entry node. This node encrypts your traffic and sends it to another random node in the network.
    The traffic is relayed through multiple nodes. Each node decrypts the traffic, re-encrypts it, and sends it to the next node in the chain.
    The traffic eventually reaches an exit node. This node decrypts the traffic and sends it to the destination website.
    By routing your traffic through multiple layers, TOR makes it difficult for anyone to identify your IP address or track your browsing history. This helps to protect your privacy and anonymity online.
    It's important to note that while TOR provides a high level of privacy, it's not completely anonymous. There are still ways for experienced attackers to track your online activity, especially if you use other services that reveal your identity.


43.Mining in the Context of Cryptocurrency
    Mining is the process of verifying transactions and creating new blocks on a blockchain network. This process is essential for maintaining the security and integrity of the blockchain.
    Bitcoin and Ethereum Mining
    Bitcoin: Bitcoin mining involves solving complex mathematical puzzles to create new blocks and verify transactions. Miners are rewarded with newly minted Bitcoin for their efforts.
    Ethereum: Ethereum mining is similar to Bitcoin, but it involves solving cryptographic puzzles known as "proof-of-work" puzzles. Miners are rewarded with Ether, the native cryptocurrency of the Ethereum network.
    Proof of Work (PoW) vs. Proof of Stake (PoS)
    Proof of Work (PoW): The traditional consensus mechanism used by Bitcoin and Ethereum. Miners compete to solve complex puzzles, and the first miner to find a solution adds a new block to the blockchain.
    Proof of Stake (PoS): A newer consensus mechanism that rewards miners based on the amount of cryptocurrency they hold, rather than their computing power. This can be more energy-efficient than PoW.
    It's important to note that cryptocurrency mining has faced criticism due to its high energy consumption. As a result, many cryptocurrencies have transitioned to or are exploring alternative consensus mechanisms like Proof of Stake to reduce their environmental impact.
    Mining Tools and Techniques
    ASICs (Application-Specific Integrated Circuits): Specialized hardware designed for cryptocurrency mining, offering significantly higher efficiency than general-purpose CPUs or GPUs.
    Mining Pools: Groups of miners who combine their computing power to increase their chances of finding a block and earning rewards.
    Mining Software: Software that controls mining hardware and interacts with the blockchain network.
    Bitcoin and Ethereum are both closely related to ASICs and binary:
    ASICs (Application-Specific Integrated Circuits): Both Bitcoin and Ethereum mining can benefit from ASICs optimized for their respective blockchains.
    Binary: All digital data, including Bitcoin and Ethereum transactions, is stored and transmitted in binary format. This means that information is represented using a combination of 0s and 1s.
    In summary, both Bitcoin and Ethereum mining rely on specialized hardware (ASICs) to solve complex mathematical problems in a binary format. This process is essential for securing the blockchain and creating a new cryptocurrency.
    GitHub, GitLab, and GitOps: A Comparison
    GitHub, GitLab, and GitOps are all important tools in the modern software development landscape. While they share some similarities, each has its own unique characteristics and use cases.


44.GitHub
    A popular platform for hosting and managing Git repositories.
    Features:
    Collaboration tools, including issues, pull requests, and code reviews.
    Project management features, such as milestones and wikis.
    Integration with other development tools and services.
    GitLab
    A comprehensive DevOps platform that includes Git repository hosting, continuous integration/continuous delivery (CI/CD), and other DevOps tools.
    Features:
    All the features of GitHub, plus additional tools for planning, building, testing, and deploying software.
    Integrated CI/CD pipelines for automating the software development process.
    Built-in container registry and package management.
    GitOps
    A set of practices and tools for managing infrastructure and applications using Git as the single source of truth.
    Key principles:
    Declaring the desired state of the infrastructure and applications in Git repositories.
    Using automated tools to reconcile the current state with the desired state.
    Continuous deployment of changes to production.
    In summary:
    
    GitHub is primarily a platform for hosting and managing Git repositories.
    GitLab is a more comprehensive DevOps platform that includes Git repository hosting, CI/CD, and other tools.
    GitOps is a set of practices and tools for managing infrastructure and applications using Git.
    The choice between GitHub, GitLab, or GitOps depends on the specific needs and goals of your software development team:
    
    If you simply need a platform for hosting Git repositories, GitHub may be sufficient.


    ### USING CONTAINER's IN VM , USNIG DOCKER TO ADD NGINX SEVER IN IT AND TYPING HI IN WEB SERVER  ###

        1.First I login in my AWS account . Thne I created an instance .
        2.In instance I make some changes , where I edit in network setting , where I added SSH , HTTPS , HTTP, ALL TRAFFIC , ALL TCP , ALL UDP AND CREATED AN INSTANCE.
        3.Then I open puuty add the IP address from instance and add key pair file which I have downloaded when I creating instance.
        4.After that I click on open , then my ubuntu terminal was opended , where I logined by writting ubuntu.
        5.After that I have to install docker in my OS .
        6.Then , I enter few command to install the docker
        COMMANDS ARE:
       a) curl -sL https://github.com/ShubhamTatvamasi/docker-install/raw/master/docker-install.sh | bash
        newgrp docker # this command will help us to use docker
        b)docker ps # provides a list of the Docker containers on your machine
      c)  docker --version # to check the version of docker which is installed
      d)  docker pull nginx #TO use nginx server in container
       e) docker run --name docker-nginx -p 80:80 nginx #In a web browser, enter your server’s IP address to reveal Nginx’s default landing page
      f)  ctrl + c #to stop the container from running
      g)  docker ps -a #The output reveals that the Docker container has exited
        DETACHED MODE
      h)  docker run --name docker-nginx -p 80:80 -d nginx #output is the container’s ID
       i) docker ps # provoide new information about container
     j)   docker stop docker-nginx # to stop the container
       k) docker rm docker-nginx
        l)Building a Web Page to Serve on Nginx
       m) mkdir -p ~/docker-nginx/html # Create a new directory for the website content within the home directory
       n) cd ~/docker-nginx/html # Create an HTML file to serve on the server
        o)ls
       p) cd html/
        q)ls # will show index.html file
        r) sudo vi index.html
        s) press {"i"} # help to insert in the web server
      t)  hi # write whatever you want to write I write only hi
        u) ctrl + c
       v)  shift + ;
       w) wq press {ENTER}
      x)  docker run --name docker-nginx -p 80:80 -d -v ~/docker-nginx/html:/usr/share/nginx/html nginx # Linking the container to the VM
        
        Also known as a hosted hypervisor, this type of hypervisor runs on top of an operating system as a software layer or application. Type 2 hypervisors are easier to install, configure, and use than Type 1 hypervisors, and are more user-friendly. However, Type 2 hypervisors are less efficient than Type 1 hypervisors because they negotiate resource allocation with the operating system. Examples of Type 2 hypervisors include VMware Workstation, Oracle VirtualBox, and Parallels Desktop
    If you're looking for a more comprehensive DevOps platform with built-in CI/CD and other tools, GitLab may be a better fit.
    GitOps, on the other hand, is a methodology that can be used with any Git-based platform, including GitHub or GitLab.

         
 
 
